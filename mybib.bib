@misc{https://doi.org/10.48550/arxiv.2012.09841,
  doi = {10.48550/ARXIV.2012.09841},
  
  url = {https://arxiv.org/abs/2012.09841},
  
  author = {Esser, Patrick and Rombach, Robin and Ommer, Björn},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Taming Transformers for High-Resolution Image Synthesis},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{EmotionSense,  
    author={Zhao, Bobo and Wang, Zhu and Yu, Zhiwen and Guo, Bin},
    booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computing, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},   
    title={EmotionSense: Emotion Recognition Based on Wearable Wristband},   
    year={2018},  
    volume={},  
    number={},  
    pages={346-355},  
    doi={10.1109/SmartWorld.2018.00091}
}

@inproceedings{10.1145/3501385.3543981,
author = {Gorson, Jamie and Cunningham, Kathryn and Worsley, Marcelo and O'Rourke, Eleanor},
title = {Using Electrodermal Activity Measurements to Understand Student Emotions While Programming},
year = {2022},
isbn = {9781450391948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501385.3543981},
doi = {10.1145/3501385.3543981},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},
pages = {105–119},
numpages = {15},
keywords = {electrodermal activity, emotion, retrospective interview, frustration, introductory programming},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@InProceedings{RecognizingEmotion,
author="Khan, Ali Mehmood
and Lawo, Michael",
editor="Kyriacou, Efthyvoulos
and Christofides, Stelios
and Pattichis, Constantinos S.",
title="Recognizing Emotion from Blood Volume Pulse and Skin Conductance Sensor Using Machine Learning Algorithms",
booktitle="XIV Mediterranean Conference on Medical and Biological Engineering and Computing 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="1297--1303",
isbn="978-3-319-32703-7"
}

@ARTICLE{DEAP,  author={Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},  journal={IEEE Transactions on Affective Computing},   title={DEAP: A Database for Emotion Analysis ;Using Physiological Signals},   year={2012},  volume={3},  number={1},  pages={18-31},  doi={10.1109/T-AFFC.2011.15}}

@misc{stablediffusion,
  doi = {10.48550/ARXIV.2112.10752},
  
  url = {https://arxiv.org/abs/2112.10752},
  
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {High-Resolution Image Synthesis with Latent Diffusion Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{CNNEmotionDetection,
author = {Lee, Minseop and Lee, Yun and Lim, Myo Taeg and Kang, Tae-Koo},
year = {2020},
month = {05},
pages = {3501},
title = {Emotion Recognition Using Convolutional Neural Network with Selected Statistical Photoplethysmogram Features},
volume = {10},
journal = {Applied Sciences},
doi = {10.3390/app10103501}
}

@misc{dataset,
  
  url = {https://www.kaggle.com/datasets/deadskull7/fer2013},
  
  author = {ROHIT VERMA},

  title = {Theatrical market revenue worldwide from 2002 to 2020},
  
  publisher = {Statista},
  
  year = {2022},

}


@misc{moviestats,

  url = {https://www.statista.com/statistics/260198/filmed-entertainment-revenue-worldwide-by-region/},
  
  author = {José Gabriel Navarro},

  title = {fer2013},
  
  publisher = {kaggle},
  
  year = {2018},

}

@article{FilmStim,
author = { Alexandre   Schaefer  and  Frédéric   Nils  and  Xavier   Sanchez  and  Pierre   Philippot },
title = {Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers},
journal = {Cognition and Emotion},
volume = {24},
number = {7},
pages = {1153-1172},
year  = {2010},
publisher = {Routledge},
doi = {10.1080/02699930903274322},

URL = {https://sites.uclouvain.be/ipsp/FilmStim/}

}

@article{CaseData,
author = {Sharma, Karan and Castellini, Claudio and van den Broek, Egon L. and Albu-Schaeffer, Alin and Schwenker, Friedhelm},
title = {A dataset of continuous affect annotations and physiological signals for emotion analysis},
year = {2019},
doi = {10.1038/s41597-019-0209-0},
journal = {Scientific Data},
volume = {6}
}


@InProceedings{EEGEmotion,
author={Nazmi Sofian Suhaimi
and James Mountstephens
and Jason Teocorresponding},
title={REEG-Based Emotion Recognition: A State-of-the-Art Review of Current Trends and Opportunities},
}

@article{CHEN2021106662,
title = {Selection and validation of emotional videos: Dataset of professional and amateur videos that elicit basic emotions},
journal = {Data in Brief},
volume = {34},
pages = {106662},
year = {2021},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2020.106662},
url = {https://www.sciencedirect.com/science/article/pii/S2352340920315419},
author = {HongYi Chen and Kai Ling Chin and Chrystalle B.Y. Tan},
keywords = {Cross-cultural, Emotional videos, Emotion elicitation, Emotion recognition, Emotional intensity},

}

@article{SpeechEmotionRecognize,
author = {Burkhardt, Felix and Sendlmeier, Walter},
year = {2003},
month = {05},
pages = {},
title = {Verification of Acousical Correlates of Emotional Speech using Formant-Synthesis},
journal = {Proceedings of the ISCA Workshop on Speech and Emotion}
}

@article{FaceEmotionRecognize,
author = {Adolphs, Ralph},
year = {2002},
month = {04},
pages = {21-62},
title = {Recognizing Emotion From Facial Expressions: Psychological and Neurological Mechanisms},
volume = {1},
journal = {Behavioral and cognitive neuroscience reviews},
doi = {10.1177/1534582302001001003}
}

@misc{GSR_Article,
author = {SBryn Farnsworth},
title = {What is GSR (galvanic skin response) and how does it work?},
year = {2018},
url = {https://imotions.com/blog/gsr},
}

@misc{InferringEmotionalState,
author = {Bhushan S. Atote and Taranpreet Singh Saini and Dr. Mangesh Bedekar and Saniya Zahoor},
title = {Inferring Emotional State of a User by User Profiling},
year = {2016},
url ={https://www.researchgate.net/publication/311703646_Inferring_Emotional_State_of_a_User_by_User_Profiling},
}

@misc{UserProfiling,
author = {Sumitkumar Kanoje and Sheetal Girase and Debajyoti Mukhopadhyay},
title = {User Profiling for Recommendation System},
year = {2015},
url = {https://www.researchgate.net/publication/274012242_User_Profiling_for_Recommendation_System},
}

@inproceedings{Arapakis,
author = {Arapakis, Ioannis and Moshfeghi, Yashar and Joho, Hideo and Ren, Reede and Hannah, David and Jose, Joemon},
year = {2009},
month = {06},
pages = {1440-1443},
title = {Integrating facial expressions into user profiling for the improvement of a multimodal recommender system},
journal = {Proceedings - 2009 IEEE International Conference on Multimedia and Expo, ICME 2009},
doi = {10.1109/ICME.2009.5202773}
}

@misc{EEG_Article,
author = {https://www.mayoclinic.org/},
title = {EEG (electroencephalogram)},
url = {https://www.mayoclinic.org/tests-procedures/eeg/about/pac-20393875},
}

@misc{WhatIsObjectDetection,
author = {https://www.mathworks.com/},
title = {What Is Object Detection?},
url = {https://www.mathworks.com/discovery/object-detection.html},
}

@misc{WhatIsUserProfiling,
author = {Data Defined},
title = {What Is A User Profile?},
url = {https://www.indicative.com/resource/user-profile/},
}

@article{BVP_Article,
title = {Exploring the blood volume amplitude and pulse transit time during anger recall in patients with coronary artery disease},
journal = {Journal of Cardiology},
volume = {65},
number = {1},
pages = {50-56},
year = {2015},
issn = {0914-5087},
doi = {https://doi.org/10.1016/j.jjcc.2014.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0914508714001075},
author = {I-Mei Lin and Sheng-Yu Fan and Ye-Hsu Lu and Chee-Siong Lee and Kuan-Ta Wu and Hui-Jing Ji},
keywords = {Blood volume amplitude, Pulse transit time, Anger recall, Coronary artery disease},
}

@misc{PPG_Article,
author = {Susha Cheriyedath, M.Sc.
Reviewed by Yolanda Smith, B.P},
title = {Photoplethysmography (PPG)},
url = {https://www.news-medical.net/health/Photoplethysmography-(PPG).aspx},
}

@inproceedings{Experiment8EmotionCategories,
author = {Healey, Jennifer},
year = {2002},
month = {01},
pages = {},
title = {Physiological user interfaces}
}

@misc{cinematronic,
author = {Cinematronic},
url = {https://cinematronic.dk/}
}

@misc{ApexOfFear,
author = {Aarhus University - Recreational Fear Lab},
title = {APEX of Fear: New Project at the Lab},
year = {2021},
url = {https://cc.au.dk/en/recreational-fear-lab/news-and-events/show/artikel/apex-of-fear-new-project-at-the-lab}
}

@misc{EMG_Article,
author = {https://www.hopkinsmedicine.org/},
title = {Electromyography (EMG)},
url = {https://www.hopkinsmedicine.org/health/treatment-tests-and-therapies/electromyography-emg},
}

@misc{CLAS,
doi = {10.21227/ybsw-yr53},
url = {https://dx.doi.org/10.21227/ybsw-yr53},
author = {Markova, Valentina},
publisher = {IEEE Dataport},
title = { Database for Cognitive Load Affect and Stress recognition },
year = {2020} } 

@Inbook{IAPS,
author="Bradley, Margaret M.
and Lang, Peter J.",
editor="Zeigler-Hill, Virgil
and Shackelford, Todd K.",
title="International Affective Picture System",
bookTitle="Encyclopedia of Personality and Individual Differences",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="1--4",
isbn="978-3-319-28099-8",
doi="10.1007/978-3-319-28099-8_42-1",
url="https://doi.org/10.1007/978-3-319-28099-8_42-1"
}

@article{FilmClips,
    author = {Barbra Zupan and Michelle Eskritt},
    title = {Eliciting emotion ratings for a set of film clips: A preliminary archive for research in emotion},
    journal = {The Journal of Social Psychology},
    volume = {160},
    number = {6},
    pages = {768-789},
    year  = {2020},
    publisher = {Routledge},
    doi = {10.1080/00224545.2020.1758016},
    note ={PMID: 32419668},
    URL = {https://doi.org/10.1080/00224545.2020.1758016},
    eprint = {https://doi.org/10.1080/00224545.2020.1758016}
}

@article{ValArouModelOrg,
  title={A circumplex model of affect.},
  author={Russell, James A},
  journal={Journal of personality and social psychology},
  volume={39},
  number={6},
  pages={1161},
  year={1980},
  publisher={American Psychological Association}
}

@INPROCEEDINGS{ModifielValArou,
    author={Kai Sun and Junqing Yu and Yue Huang and Xiaoqiang Hu},  
    booktitle={2009 IEEE International Conference on Multimedia and Expo},   
    title={An improved valence-arousal emotion space for video affective content representation and recognition},   
    year={2009},  
    volume={},  
    number={},  
    pages={566-569},  
    doi={10.1109/ICME.2009.5202559}
}

@misc{AffectiveComputing, 
author={Picard, R. W. (1995). Affective Computing. M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 321.}}

@INPROCEEDINGS{BioSignalsEmotionModel,  
    author={Rathod, Priyank and George, Kiran and Shinde, Nikhil},  
    booktitle={2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN)},   
    title={Bio-signal based emotion detection device},   
    year={2016}, 
    pages={105-108},  
    doi={10.1109/BSN.2016.7516241}
}

@article{des-boyle,
title = {Reliability and validity of Izard's differential emotions scale},
journal = {Personality and Individual Differences},
volume = {5},
number = {6},
pages = {747-750},
year = {1984},
issn = {0191-8869},
doi = {https://doi.org/10.1016/0191-8869(84)90124-7},
url = {https://www.sciencedirect.com/science/article/pii/0191886984901247},
author = {Gregory J. Boyle},
}

@book{humanemotionsIzard,
title = {Human Emotions},
author = {Carroll E. Izard},
publisher = {Springer New York},
isbn = {978-0-306-30986-1},
doi = {https://doi.org/10.1007/978-1-4899-2209-0},
year = {1977}
}

@book{ekmanEmotions,
edition = {paperback ed.},
isbn = {9780753817650},
keywords = {Emotions},
language = {eng},
publisher = {Phoenix},
series = {A Phoenix paperback.},
title = {Emotions revealed :  understanding faces and feelings.},
year = {2004},
abstract = {This title provides a map to the world of emotions.},
author = {Ekman, Paul.},
address = {London},
}

@article{desiv,
  title={Stability of emotion experiences and their relations to traits of personality.},
  author={Carroll E. Izard and D Z Libero and Priscilla H. Putnam and O. Maurice Haynes},
  journal={Journal of personality and social psychology},
  year={1993},
  volume={64 5},
  pages={847-60},
  doi = {https://doi.org/10.1037/0022-3514.64.5.847}
}

@article{desivBoyle,
author = {Boyle, Gregory J.},
year = {2012},
month = {11},
pages = {56-66},
title = {Factor Structure of the Differential Emotions Scale and the Eight State Questionnaire Revisited},
volume = {10},
journal = {The Irish Journal of Psychology},
doi = {10.1080/03033910.1989.10557734}
}

@article{ekman1992argument,
  title={An argument for basic emotions},
  author={Ekman, Paul},
  journal={Cognition \& emotion},
  volume={6},
  number={3-4},
  pages={169--200},
  year={1992},
  publisher={Taylor \& Francis}
}








@article{EmotionsWatchingMovies,
author = { Anne   Bartsch },
title = {Emotional Gratification in Entertainment Experience. Why Viewers of Movies and Television Series Find it Rewarding to Experience Emotions},
journal = {Media Psychology},
volume = {15},
number = {3},
pages = {267-302},
year  = {2012},
publisher = {Routledge},
doi = {10.1080/15213269.2012.693811},

URL = { 
        https://doi.org/10.1080/15213269.2012.693811
    
},
eprint = { 
        https://doi.org/10.1080/15213269.2012.693811
}}

@phdthesis{CGIPurpose,
  title={Groundbreaking CGI in Hollywood Films},
  author={Gotovac, Luka Antonio},
  year={2018},
  school={University of Zadar. Department of English}
}


@misc{AppleWatch,
author = {Apple},
title = {Which Apple Watch
is right for you?},
addendum={Visited on 23/11 2022},
url = {https://www.apple.com/watch/compare/},
}

@misc{gsrwatch,
author = {Niel Smith},
title = {Galvanic Skin Sensor technology on wearables is just getting started},
howpublished = {\url{https://www.myhealthyapple.com/galvanic-skin-sensor-technology-on-wearables-is-just-getting-started/}},
addendum = {Visited on 23/11 2022}
}

@misc{fitbitSense,
author = {Fitbit LLC},
title = {General Info and Specifications | Fitbit Sense},
howpublished = {\url{https://help.fitbit.com/manuals/sense/Content/manuals/html/General\%20Info\%20and\%20Specifications.htm}},
addendum = {Visited on 23/11 2022}
}

@misc{shimmer3,
    author = {Shimmer},
    title = {Shimmer3 GSR+ Unit},
    howpublished = {\url{https://shimmersensing.com/product/shimmer3-gsr-unit/}},
    addendum = {Visited on 23/11 2022}
}

@misc{BLIP,
  doi = {10.48550/ARXIV.2201.12086},
  
  url = {https://arxiv.org/abs/2201.12086},
  
  author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{PPG_EMG_CNN,
title = "PPG and EMG based emotion recognition using convolutional neural network",
abstract = "Emotion recognition is an essential part of human computer interaction and there are many sources for emotion recognition. In this study, physiological signals, especially electromyogram (EMG) and photoplethysmogram (PPG) are used to detect the emotion. To classify emotions in more detail, the existing method of modeling emotion which represents the emotion as valence and arousal is subdivided by four levels. Convolutional Neural network (CNN) is adopted for feature extraction and emotion classification. We measure the EMG and PPG signals from 30 subjects using selected 32 videos. Our method is evaluated by what we acquired from participants.",
keywords = "Arousal, Convolutional neural network, EMG, PPG, Physiological signal, Valence",
author = "Lee, {Min Seop} and Cho, {Ye Ri} and Lee, {Yun Kyu} and Pae, {Dong Sung} and Lim, {Myo Taeg} and Kang, {Tae Koo}",
note = "Publisher Copyright: Copyright {\textcopyright} 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Copyright: Copyright 2020 Elsevier B.V., All rights reserved.; 16th International Conference on Informatics in Control, Automation and Robotics, ICINCO 2019 ; Conference date: 29-07-2019 Through 31-07-2019",
year = "2019",
doi = "10.5220/0007797005950600",
language = "English",
series = "ICINCO 2019 - Proceedings of the 16th International Conference on Informatics in Control, Automation and Robotics",
publisher = "SciTePress",
pages = "595--600",
editor = "Oleg Gusikhin and Kurosh Madani and Janan Zaytoon",
booktitle = "ICINCO 2019 - Proceedings of the 16th International Conference on Informatics in Control, Automation and Robotics",
}